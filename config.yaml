target: first-stage-training # first-stage-training, diffusion-training, inference
data:
    first_stage:
        target_shape:   [64, 128, 128]
        n_samples:      -1
        train_ratio:    0.8
        modalities:
        - flair
        - seg
        binarize:       true
        npy_path:       ./data/brats_preprocessed.npy
        root_path:      ../common_data/RSNA_ASNR_MICCAI_BraTS2021_TrainingData_16July2021
        batch_size:     8
        shuffle:        true
        num_workers:    6
    diffusion:
        latent_shape:   [4, 32, 32]
        n_samples:      500
        to_2d:          true
        root_pat:       ./data/brats_preprocessed.npy
        npy_path:       ./data/brats_preprocessed_latents.npy
        batch_size:     8
        shuffle:        true
        num_workers:    6
unet:
    image_size:                 [128, 128] # [64, 32, 32]
    dims:                       2
    in_channels:                2
    out_channels:               2
    model_channels:             128
    num_res_blocks:             2
    max_period:                 1000
    num_heads:                  8
    num_heads_upsample:         -1
    num_head_channels:          -1
    attention_resolutions:      [16, 8]
    channel_mult:               [1, 2, 3, 4, 4]
    dropout:                    0.1
    class_cond:                 false
    use_checkpoint:             false
    use_scale_shift_norm:       true
    resblock_updown:            false
    use_new_attention_order:    false
    conv_resample:              true
    num_classes:                # empty
    precision:                  32
autoencoder:
    target:         VQAutoencoder # specifies which autoencoder to use
    input_shape:    [2, 64, 64] # channels, height, width
    n_embed:        8192
    embed_dim:      2
    num_channels:   128
    channels_mult:  [1, 2, 4]
    attn:           [False, False, True]
    num_res_blocks: 2
    temb_dim:       128
    max_period:     64 
    dropout:        0.2
    z_channels:     2
    z_double:       false
    tanh:           true
    use_emas:       false
    learning_rate:  4.5e-06
    loss:
        disc_start:         10001
        codebook_weight:    1.0
        pixel_weight:       1.0
        perceptual_weight:  1.0
        disc_weight:        0.5
        disc_input_channels: 2
        disc_channels:      64
        disc_num_layers:    3
        disc_factor:        1.0
        lr_d_factor:        1.0
        logvar_init:        0.0
        kl_weight:          1.0e-05
diffusion:
    learn_sigma:            false
    T:                      1000
    beta_schedule:          cosine
    model_mean_type:        epsilon
    model_var_type:         fixed_small
    loss_type:              mse
    input_perturbation:     0.1
    timestep_respacing:
    use_kl:                 false
    predict_xstart:         false
    rescale_timesteps:      false
    rescale_learned_sigmas: false
    schedule_sampler:       uniform # not sure of loss-aware works well
    loss_memory_span:       10
callbacks:
    checkpoint:
        monitor: 
        dirpath:            ./checkpoints
        save_top_k:         1
        every_n_epochs:     50
